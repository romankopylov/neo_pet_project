{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b41f8bc-b44b-4ad8-ac73-2fa78ebe8aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825234c-1341-45e3-a517-92e87f16877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "path = \"/home/roman/homework/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15833839-c483-4529-b4d1-af9164876cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f60da-e156-475d-a86c-9ece9fba2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание списка кортежей с данными\n",
    "data = [(1, 'swimming', 'summer'),\n",
    "        (2, 'rhythmic gymnastics', 'summer'),\n",
    "        (3, 'athletics', 'summer'),\n",
    "        (4, 'football', 'summer'),\n",
    "        (5, 'weightlifting', 'summer'),\n",
    "        (6, 'hockey', 'winter'),\n",
    "        (7, 'wrestling', 'winter'),\n",
    "        (8, 'badminton', 'winter'),\n",
    "        (9, '3x3 basketball', 'winter'),\n",
    "        (10, 'water polo', 'winter'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75ad23-cf4b-4cb5-a67f-83644b1b2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame\n",
    "schema = \"row_id BIGINT, discipline STRING, season STRING\"\n",
    "discDF = spark.createDataFrame(data, schema)\n",
    "discDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6fca3-3810-47ef-a1ce-846e9fd583ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение disciplines в csv-файл\n",
    "discDF.repartition(1).write.csv(f\"{path}disciplines.csv\", header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc5013-1e64-43af-86f6-f4c07578cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение файла \"Athletes.csv\" и загрузка данных в DataFrame\n",
    "athDF = spark.read.csv(f'{path}Athletes.csv', header=True, inferSchema=True, sep=\";\")\n",
    "athDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988ea3e-ecb7-4bc2-8d94-0150abbdab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет количества спортсменов в каждой дисциплине\n",
    "countDF = athDF.groupBy('Discipline').count().orderBy('count', ascending=False)\n",
    "countDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5044ff-ccc8-46a9-85e4-ef6ffaf98c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение count_by_discipline в формате parquet в указанную директорию\n",
    "countDF.write.parquet(f\"{path}count_by_disciplines.parquet\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdaf563-720d-4090-825e-7cc6205d3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование данных колонки discipline в нижний регистр\n",
    "countDF = countDF.withColumn(\"discipline\", F.lower(countDF.Discipline))\n",
    "countDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff941896-3505-42d7-87a7-3b6533f1ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение датафреймов по колонке \"discipline\"\n",
    "resultDF = countDF.join(discDF, on='discipline', how='inner').select('discipline', 'count')\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c0a6a-6d8b-4315-a531-f4b80dd261e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохранение result в формате parquet в указанную директорию\n",
    "resultDF.write.parquet(f\"{path}result.parquet\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c34813-bb0e-48b2-8498-b9152f2608fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(f\"{path}result.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559dbb8d-8585-4155-af7a-2b3798589648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
